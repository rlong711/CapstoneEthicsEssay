---
title: "Lawsuits against Meta in a Kenyan Court? The Horrifying Realities and Labor Practices of Meta’s Content Moderation Project."
author: 
  name: Raley Long
  corresponding: true
  email: rlong@smith.edu
  affiliations: Smith College 
format: 
  pdf: default 
keywords: 
  - "Data Ethics" 
  - "Meta" 
  - "Content Algorithms" 
  - "Content Moderation"
  - "Sama" 
  - "Inter alia" 
  - "Foxglove" 
  - "American Statistical Association" 
  - "The Meta Code of Conduct"
abstract: "Something" 
date: last-modified 
bibliography: references.bib
number-sections: true
editor: visual
---

	In the early years of the spread of social networking applications, various companies positioned their products as the next frontier of human connection. Early social networking companies such as Facebook, Myspace, and Friendster positioned their platforms as a step towards a tech-forward utopian society where humans connect and spread information and cultural understandings on an unprecedented scale. In reality, it feels as if these companies opened up Pandora's box. Facebook and, by extension, Meta, serve a useful example of this idea, where users in real time have observed the reality that hateful and extreme rhetoric and imagery not only exist but thrive on the platform. 
After calls for the regulation of content on these sites, Meta created a seemingly robust system for content moderation. This system includes the work of real, human content moderators who go through flagged content to determine if it should be taken down. These content moderators are so crucial to Meta’s work to remove harmful content online that Meta’s Code of Conduct cites them as an integral part of ensuring that they maintain a level of ethical integrity when it comes to what they, as a company, allow on their platform [@MetaCodeofConduct, 30]. For many social networking sites, this sort of content moderation became a standard, and there are extensive reports about p the harm done to the individuals employed to sift through the most toxic content on these sites. This manifested for Meta in the form of three lawsuits from surrounding their African-language content moderation team based in Kenya that focus on accusing Meta of unlawful labor practices, a lack of meaningful support for content moderator, and amplifying violence in Ethiopia during a recent civil conflict. Unlike Meta’s legal counsel, this investigation is not concerned with Meta’s legal responsibility to these plaintiffs. Rather, this investigation hopes to highlight how Meta failed and continues to fail to uphold their ethical standards as outlined in their publicly available code of conduct. Meta’s amplification of hate speech and violence is in direct contradiction with their ethical code, and Meta’s refusal to take meaningful accountability for the harm done to these content moderators goes against the responsibilities Meta has to their personnel and to respecting foreign sovereignty. It is through the obscurification of the labor of content moderators and the blaming of ‘contractors’ that Meta works to discard their ethical responsibility.  
	The first case brought against Meta in this collection regards the allegation that Meta’s platforms propagated abuses against the Tigrayan community during conflict in northern Ethiopia from November 2020 to November 2022 [@AmnestyEthiopia]. In 2023, Amnesty International published a 74-page report entitled “A Death Sentence for My Father: Meta’s Contribution to Human Rights Abuses in Northern Ethiopia” which outlined how Meta’s Facebook platform’s ‘surveillance-based business model’ fanned the flames of ethnic violence in response to reports by the whistleblower Frances Haugen and from those who lost loved ones in direct connection to Facebooks content an rhetoric [@AmnestyEthiopia]. In the case of Abrham Merag, a photo of his father, a member of the Tigrayan minority, which included his full name and place of work, failed to be taken down after being reported to moderators at Meta, ultimately leading to his murder in November of 2021 [@EconomistMeta]. Notably, Amnesty International reported on the role Facebook’s platform played in spreading violent and hateful rhetoric against the Rohingya ethnic minority in Myanmar beginning in August 2017[@AmnestyMyanmar]. According to Amnesty International, this report regarding Facebook’s role in the violence committed against the Tigrayan community affirms that since this first allegation, Meta has failed to meaningfully reform their business model and content-shaping algorithms [@AmnestyEthiopia]. In the foreword of Meta’s Code of Conduct, written by its founder Mark Zuckerberg, he claims that “the importance of [Meta’s] work means [Meta] must all commit to holding [themselves] to a high standard.” [@MetaCodeofConduct] To that end, the code of conduct goes on to assert that Meta is “committed to protecting [their] communities from harm” and that “[working] to identify and address such risk is a fundamental part of [their] commitment to safety.” [@MetaCodeofConduct, 30] Clearly, there was a failure to address the human rights violations outlined in Amnesty International’s initial report regarding Myanmar, which suggests a lack of commitment Meta has to their ethical responsibilities they have outlined for themselves. Eventually, the allegations outlined in Amnesty International’s report made their way to the court system, where once again, Meta failed s to uphold their ethical responsibilities. 
	In 2024, two Ethiopian citizens, Abrham Meareg, mentioned earlier, and Fisseha Tekle, supported by a Kenyan civil society organization, The Katiba Institute, brought a case forward about Meta’s role in exacerbating ethnic violence in Ethiopia to the Kenyan High Court [@AmnestyKenya]. Although the violence occurred in Ethiopia, the plaintiffs argue that since the moderators for the African language regions were housed in Kenya, Kenyan courts should have jurisdiction over this 2.3 billion dollar case [@EconomistMeta]. This case specifically articulates that “Facebook platform’s algorithmic recommendation systems prioritized and promoted inciteful, hateful and dangerous content on its platform… contributing to significant human rights violations.” [@AmnestyKenya] Since this case was brought forward in 2024, Meta and the plaintiffs have not had the opportunity to fully litigate this case. Notably, however, Meta’s first legal move was to argue “that the case should not be heard in Kenya because the company is registered in the US and that Meta’s terms of service require such claims to be filed in the US.” [@AmnestyKenya] This argument does not align with the policies outlined in their code of conduct regarding ‘interacting with governments and political entities' responsibility.’ [@MetaCodeofConduct, 52] In this section, the code of conduct asserts that Meta’s global reach forces Meta to “engage constructively and responsibly with governments… to further Meta’s mission to build the future of human connection.” [@MetaCodeofConduct, 52] Trying to force a shutdown of this case on the grounds of jurisdiction completely contradicts this supposed commitment to respecting foreign sovereignty as outlined above. Moreover, Meta has had success with stalling cases in British and American courts more sympathetic to their economic and cultural capital regarding similar allegations surrounding Meta’s role in the Rohingya genocide in 2017 in Myanmar, outlined earlier in this investigation [@EconomistMeta]. Meta’s legal argument in Kenya, therefore, can be read as an attempt to evade meaningful justice and calls for changes to their incredibly lucrative algorithm and business model. This goes against Meta’s stated foundational principle as outlined in their code of conduct to “give people a voice… to tell their stories, to share, to connect, to be heard and to change their lives for the better.” [@MetaCodeofConduct] Meta’s attempt to avoid responsibility remains unsuccessful since in April of 2025, a Kenyan High Court ruled that they do in fact have jurisdiction to try this case and plan to do so [@AmnestyKenyaUpdate].
	Meta not only fails to moderate their content, but also fails their content moderators. Regarding Kenyan courts in particular, there have been two cases brought against Facebook by content moderators, its parents company Meta, and affiliated contractors in charge of content moderation in the African language regions, specficially Sama, primarily, alleging “human trafficking…, irregular pay, inadequate mental health support, union busting, and violations of workers’ privacy and dignity.” [@BusinessLawsuit] In response to these two cases, Meta “refused to argue the merits of the case, instead insisting that Kenyan courts don’t have the power to hear it” [@Foxglove] and attempted to claim that personnel working under an outside contractor, Sama in this case, cannot consider Meta their legal employer [@BusinessLawsuit]. In 2024, Kenyan courts rejected these arguments and the cases continue to be litigated. As detailed earlier in this investigation, Meta’s attempts to bypass justice, accountability, and good-faith investigation contradicts their commitment to respecting foreign sovereignty and commitment to maintaining a safe platform. Moreover, Meta’s denial of responsibility for those employed by their own contractor violates their assertion in their code of conduct that these ethical responsibilities and rights extend to all personell “including vendor workers, contractors, and independent contractors.” [@MetaCodeofConduct, 6] This suggests that Meta is disregarding this ethical commitment to shield themselves from legal liability and possible financial and reputational damage.
Regardless of the outcome of these cases, the allegations laid out and Meta’s initial responses to these cases betray their ultimate negligence by their own ethical standards. As calls for improved content moderation increased, Meta rightfully created more avenues for making their platform more safe. Clearly, these efforts have not been substantive enough and the treatment of the content moderators tasked with doing this crucial work contradicts the ethical responsibility towards their employees and whistle-blowers outlined in Meta’s code of conduct. The relationship between these Western tech giants and contractors in the global South has always been exploitative, and the rise in cases across the Global South against these companies reflect this fact. It is no wonder then that the leadership of these technology firms are seeking refuge in the arms of increasingly fascist governments who inherently reject international law. 
	
	
	
	

